---
#env: Connect4
env: TicTacToe

agent_config:
  agent1:
    agent: AlphaZero
    augment_input: true
    batch_size: 8
    c: 1.41
    dirichlet_noise: 1
    epochs: 25
    epsilon: 0
    dropout: 0.3
    input_width: 3
    input_height: 3
    lr: 0.001
    max_mem_size: 10000
    momentum: 0.9
    n_sim: 15
    network_path: ""
    network_type: "cnn_small"
    num_channels: 32
    output_size: 9
    optimizer: Adam
    player: 1
    minimax_lookup_path: # For mimimax loss
    state_lookup_path:
    t_threshold: 2
    weight_decay: 0

  agent2:
    agent: TicTacToeMinMax
    player: 2
    type: "alphabeta"


exp_config: # experiment config
  episodes: 15 # total number of episodes to run
  exp_name: alphago
  logger_type: tensorboard # what source to use for logging experiments.
  neptune_api_token: neptune_api_key
  neptune_name: neptune_user_name/sandbox
  plot_data: true
  record_all: true
  record_every: 1 # how often to record info
  eval_iters: 1 # number of games to player during evaluation
  eval_threshold: 1
  render: false
  run_evaluator: false
  run_minimax_eval: true
  save_model: true
  train_iters: 10 # number of games to play per episode
